{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eef529b-1374-4a88-abd9-eea3b8c63f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting RAG data store generation...\n",
      "ğŸ“š Loaded 1 documents from data/books\n",
      "âœ‚ï¸ Split 1 documents into 801 chunks.\n",
      "\n",
      "ğŸ“„ Sample chunk:\n",
      "--------------------------------------------------\n",
      "So she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure of\n",
      "making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
      "close by her.\n",
      "\n",
      "ğŸ“‹ Metadata: {'source': 'data\\\\books\\\\alice_in_wonderland.md', 'start_index': 1654}\n",
      "--------------------------------------------------\n",
      "ğŸ—‘ï¸ Removing existing database at chroma\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n",
      "ğŸ“¥ Downloading model (first time only)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamur\\AppData\\Local\\Temp\\ipykernel_30264\\537138576.py:100: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "D:\\Applications\\DataScience\\RAG_prototype\\ragproto\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ’¾ Creating Chroma database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "C:\\Users\\kamur\\AppData\\Local\\Temp\\ipykernel_30264\\537138576.py:112: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 801 chunks to chroma\n",
      "\n",
      "ğŸ‰ Data store generation completed successfully!\n",
      "ğŸ“ Database location: chroma\n",
      "ğŸ” Verifying data store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database verification successful!\n",
      "ğŸ“Š Found 3 results for test query 'Alice'\n",
      "ğŸ“ Sample result: CHAPTER XII.\n",
      "Aliceâ€™s Evidence...\n"
     ]
    }
   ],
   "source": [
    "# RAG Data Store Generator with HuggingFace Embeddings\n",
    "# Complete code for Jupyter Notebook\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load environment variables (optional since we're not using OpenAI)\n",
    "load_dotenv(dotenv_path=\".env.txt\", override=True)\n",
    "\n",
    "# Configuration\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"data/books\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to generate the data store.\"\"\"\n",
    "    generate_data_store()\n",
    "\n",
    "def generate_data_store():\n",
    "    \"\"\"Generate the vector database from documents.\"\"\"\n",
    "    print(\"ğŸš€ Starting RAG data store generation...\")\n",
    "    \n",
    "    # Load documents\n",
    "    documents = load_documents()\n",
    "    if not documents:\n",
    "        print(\"âŒ No documents found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunks = split_text(documents)\n",
    "    if not chunks:\n",
    "        print(\"âŒ No chunks created. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Save to vector database\n",
    "    save_to_chroma(chunks)\n",
    "    \n",
    "    print(\"\\nğŸ‰ Data store generation completed successfully!\")\n",
    "    print(f\"ğŸ“ Database location: {CHROMA_PATH}\")\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Load documents from the specified directory.\"\"\"\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"Error: Data path {DATA_PATH} does not exist.\")\n",
    "        return []\n",
    "    \n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "    documents = loader.load()\n",
    "    print(f\"ğŸ“š Loaded {len(documents)} documents from {DATA_PATH}\")\n",
    "    return documents\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "    \"\"\"Split documents into smaller chunks for better embedding.\"\"\"\n",
    "    if not documents:\n",
    "        print(\"No documents to split.\")\n",
    "        return []\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"âœ‚ï¸ Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    \n",
    "    # Display sample chunk information\n",
    "    if chunks:\n",
    "        sample_idx = min(10, len(chunks) - 1)\n",
    "        document = chunks[sample_idx]\n",
    "        print(\"\\nğŸ“„ Sample chunk:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(document.page_content)\n",
    "        print(f\"\\nğŸ“‹ Metadata: {document.metadata}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "    \"\"\"Save document chunks to Chroma vector database using HuggingFace embeddings.\"\"\"\n",
    "    if not chunks:\n",
    "        print(\"No chunks to save.\")\n",
    "        return\n",
    "    \n",
    "    # Clear out the existing database\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        print(f\"ğŸ—‘ï¸ Removing existing database at {CHROMA_PATH}\")\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "    \n",
    "    # Create HuggingFace embeddings\n",
    "    print(\"ğŸ¤— Initializing HuggingFace embeddings...\")\n",
    "    print(\"ğŸ“¥ Downloading model (first time only)...\")\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    print(\"âœ… HuggingFace embeddings loaded successfully!\")\n",
    "    \n",
    "    # Create and save the vector database\n",
    "    print(\"ğŸ’¾ Creating Chroma database...\")\n",
    "    db = Chroma.from_documents(\n",
    "        chunks, \n",
    "        embeddings, \n",
    "        persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    db.persist()\n",
    "    print(f\"âœ… Saved {len(chunks)} chunks to {CHROMA_PATH}\")\n",
    "\n",
    "def verify_data_store():\n",
    "    \"\"\"Verify that the data store was created successfully.\"\"\"\n",
    "    print(\"ğŸ” Verifying data store...\")\n",
    "    \n",
    "    if not os.path.exists(CHROMA_PATH):\n",
    "        print(\"âŒ Chroma database was not created successfully.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Try to load the database\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "        \n",
    "        # Test a simple query\n",
    "        results = db.similarity_search(\"Alice\", k=3)\n",
    "        print(f\"âœ… Database verification successful!\")\n",
    "        print(f\"ğŸ“Š Found {len(results)} results for test query 'Alice'\")\n",
    "        \n",
    "        if results:\n",
    "            print(f\"ğŸ“ Sample result: {results[0].page_content[:100]}...\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Database verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def query_database(query: str, k: int = 5):\n",
    "    \"\"\"Query the vector database for similar chunks.\"\"\"\n",
    "    if not os.path.exists(CHROMA_PATH):\n",
    "        print(\"âŒ Database not found. Run generate_data_store() first.\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "        \n",
    "        results = db.similarity_search(query, k=k)\n",
    "        print(f\"ğŸ” Query: '{query}'\")\n",
    "        print(f\"ğŸ“Š Found {len(results)} similar chunks:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. {result.page_content[:200]}...\")\n",
    "            print(f\"   ğŸ“ Source: {result.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Query failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Execution logic\n",
    "if __name__ == \"__main__\":\n",
    "    # If running as script\n",
    "    main()\n",
    "    verify_data_store()\n",
    "else:\n",
    "    # If imported in Jupyter notebook\n",
    "    print(\"ğŸ“š RAG Data Store Generator loaded!\")\n",
    "    print(\"\\nğŸš€ Available functions:\")\n",
    "    print(\"  â€¢ generate_data_store() - Create the vector database\")\n",
    "    print(\"  â€¢ verify_data_store() - Test the database\")\n",
    "    print(\"  â€¢ query_database('your query') - Search the database\")\n",
    "    print(\"\\nğŸ’¡ Quick start: Run generate_data_store()\")\n",
    "\n",
    "# Auto-run if this is the main execution\n",
    "# Uncomment the lines below to auto-execute when running the cell\n",
    "# generate_data_store()\n",
    "# verify_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b244a001-c60b-4308-8e43-da939cdbc0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤— Starting HuggingFace Embeddings Demo...\n",
      "ğŸ“¥ Loading HuggingFace embeddings model...\n",
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "\n",
      "ğŸ Getting embedding for 'apple'...\n",
      "ğŸ“Š Vector for 'apple': [-0.006138438358902931, 0.0310117956250906, 0.06479357928037643, 0.010941504500806332, 0.0052671851590275764]... (showing first 5 dimensions)\n",
      "ğŸ“ Vector length: 384 dimensions\n",
      "ğŸ”¢ Vector data type: <class 'float'>\n",
      "\n",
      "ğŸ” Comparing 7 word pairs...\n",
      "============================================================\n",
      "\n",
      "ğŸ” Advanced comparison between 'apple' and 'iphone':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.7238\n",
      "ğŸ“ Cosine Distance: 0.2762\n",
      "ğŸ“ Euclidean Distance: 0.7432\n",
      "ğŸ’› Moderately similar words\n",
      "\n",
      "ğŸ” Advanced comparison between 'apple' and 'orange':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.3726\n",
      "ğŸ“ Cosine Distance: 0.6274\n",
      "ğŸ“ Euclidean Distance: 1.1202\n",
      "â¤ï¸ Quite different words\n",
      "\n",
      "ğŸ” Advanced comparison between 'car' and 'automobile':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.8645\n",
      "ğŸ“ Cosine Distance: 0.1355\n",
      "ğŸ“ Euclidean Distance: 0.5205\n",
      "ğŸ’š Very similar words\n",
      "\n",
      "ğŸ” Advanced comparison between 'happy' and 'sad':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.3727\n",
      "ğŸ“ Cosine Distance: 0.6273\n",
      "ğŸ“ Euclidean Distance: 1.1201\n",
      "â¤ï¸ Quite different words\n",
      "\n",
      "ğŸ” Advanced comparison between 'dog' and 'computer':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.4250\n",
      "ğŸ“ Cosine Distance: 0.5750\n",
      "ğŸ“ Euclidean Distance: 1.0724\n",
      "ğŸ§¡ Somewhat similar words\n",
      "\n",
      "ğŸ” Advanced comparison between 'king' and 'queen':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6807\n",
      "ğŸ“ Cosine Distance: 0.3193\n",
      "ğŸ“ Euclidean Distance: 0.7991\n",
      "ğŸ’› Moderately similar words\n",
      "\n",
      "ğŸ” Advanced comparison between 'paris' and 'france':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.7331\n",
      "ğŸ“ Cosine Distance: 0.2669\n",
      "ğŸ“ Euclidean Distance: 0.7306\n",
      "ğŸ’› Moderately similar words\n",
      "\n",
      "ğŸ§ª Testing LangChain's built-in evaluator...\n",
      "âœ… LangChain evaluator result for ('apple', 'iphone'): {'score': 0.2761707561468809}\n",
      "\n",
      "ğŸ“ˆ Summary of Word Pair Similarities:\n",
      "============================================================\n",
      " 1. car        â†” automobile | Similarity: 0.8645\n",
      " 2. paris      â†” france     | Similarity: 0.7331\n",
      " 3. apple      â†” iphone     | Similarity: 0.7238\n",
      " 4. king       â†” queen      | Similarity: 0.6807\n",
      " 5. dog        â†” computer   | Similarity: 0.4250\n",
      " 6. happy      â†” sad        | Similarity: 0.3727\n",
      " 7. apple      â†” orange     | Similarity: 0.3726\n",
      "\n",
      "ğŸ§ª Testing embedding quality with different word types...\n",
      "\n",
      "ğŸ“‚ Category: Animals\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Advanced comparison between 'dog' and 'cat':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6606\n",
      "ğŸ“ Cosine Distance: 0.3394\n",
      "ğŸ“ Euclidean Distance: 0.8238\n",
      "ğŸ’› Moderately similar words\n",
      "  dog â†” cat: 0.661\n",
      "\n",
      "ğŸ” Advanced comparison between 'dog' and 'elephant':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.4933\n",
      "ğŸ“ Cosine Distance: 0.5067\n",
      "ğŸ“ Euclidean Distance: 1.0066\n",
      "ğŸ§¡ Somewhat similar words\n",
      "  dog â†” elephant: 0.493\n",
      "\n",
      "ğŸ” Advanced comparison between 'dog' and 'mouse':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.3453\n",
      "ğŸ“ Cosine Distance: 0.6547\n",
      "ğŸ“ Euclidean Distance: 1.1443\n",
      "â¤ï¸ Quite different words\n",
      "  dog â†” mouse: 0.345\n",
      "\n",
      "ğŸ“‚ Category: Colors\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Advanced comparison between 'red' and 'blue':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.7294\n",
      "ğŸ“ Cosine Distance: 0.2706\n",
      "ğŸ“ Euclidean Distance: 0.7356\n",
      "ğŸ’› Moderately similar words\n",
      "  red â†” blue: 0.729\n",
      "\n",
      "ğŸ” Advanced comparison between 'red' and 'green':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6999\n",
      "ğŸ“ Cosine Distance: 0.3001\n",
      "ğŸ“ Euclidean Distance: 0.7747\n",
      "ğŸ’› Moderately similar words\n",
      "  red â†” green: 0.700\n",
      "\n",
      "ğŸ” Advanced comparison between 'red' and 'yellow':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6856\n",
      "ğŸ“ Cosine Distance: 0.3144\n",
      "ğŸ“ Euclidean Distance: 0.7929\n",
      "ğŸ’› Moderately similar words\n",
      "  red â†” yellow: 0.686\n",
      "\n",
      "ğŸ“‚ Category: Countries\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Advanced comparison between 'france' and 'germany':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.7476\n",
      "ğŸ“ Cosine Distance: 0.2524\n",
      "ğŸ“ Euclidean Distance: 0.7104\n",
      "ğŸ’› Moderately similar words\n",
      "  france â†” germany: 0.748\n",
      "\n",
      "ğŸ” Advanced comparison between 'france' and 'japan':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.5465\n",
      "ğŸ“ Cosine Distance: 0.4535\n",
      "ğŸ“ Euclidean Distance: 0.9524\n",
      "ğŸ§¡ Somewhat similar words\n",
      "  france â†” japan: 0.546\n",
      "\n",
      "ğŸ” Advanced comparison between 'france' and 'brazil':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6667\n",
      "ğŸ“ Cosine Distance: 0.3333\n",
      "ğŸ“ Euclidean Distance: 0.8164\n",
      "ğŸ’› Moderately similar words\n",
      "  france â†” brazil: 0.667\n",
      "\n",
      "ğŸ“‚ Category: Emotions\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Advanced comparison between 'happy' and 'sad':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.3727\n",
      "ğŸ“ Cosine Distance: 0.6273\n",
      "ğŸ“ Euclidean Distance: 1.1201\n",
      "â¤ï¸ Quite different words\n",
      "  happy â†” sad: 0.373\n",
      "\n",
      "ğŸ” Advanced comparison between 'happy' and 'angry':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.3906\n",
      "ğŸ“ Cosine Distance: 0.6094\n",
      "ğŸ“ Euclidean Distance: 1.1040\n",
      "â¤ï¸ Quite different words\n",
      "  happy â†” angry: 0.391\n",
      "\n",
      "ğŸ” Advanced comparison between 'happy' and 'excited':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.5768\n",
      "ğŸ“ Cosine Distance: 0.4232\n",
      "ğŸ“ Euclidean Distance: 0.9201\n",
      "ğŸ§¡ Somewhat similar words\n",
      "  happy â†” excited: 0.577\n",
      "\n",
      "ğŸ“‚ Category: Technology\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Advanced comparison between 'computer' and 'smartphone':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.4430\n",
      "ğŸ“ Cosine Distance: 0.5570\n",
      "ğŸ“ Euclidean Distance: 1.0555\n",
      "ğŸ§¡ Somewhat similar words\n",
      "  computer â†” smartphone: 0.443\n",
      "\n",
      "ğŸ” Advanced comparison between 'computer' and 'internet':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.6294\n",
      "ğŸ“ Cosine Distance: 0.3706\n",
      "ğŸ“ Euclidean Distance: 0.8609\n",
      "ğŸ’› Moderately similar words\n",
      "  computer â†” internet: 0.629\n",
      "\n",
      "ğŸ” Advanced comparison between 'computer' and 'software':\n",
      "------------------------------------------------------------\n",
      "ğŸ“Š Cosine Similarity: 0.5990\n",
      "ğŸ“ Cosine Distance: 0.4010\n",
      "ğŸ“ Euclidean Distance: 0.8955\n",
      "ğŸ§¡ Somewhat similar words\n",
      "  computer â†” software: 0.599\n",
      "\n",
      "ğŸ¯ Finding words most similar to 'apple'...\n",
      "ğŸ† Top 3 most similar words to 'apple':\n",
      "  1. computer: 0.5624\n",
      "  2. phone: 0.5307\n",
      "  3. laptop: 0.4873\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace Embeddings and Word Comparison Tool\n",
    "# Complete code for Jupyter Notebook - No OpenAI dependencies\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.evaluation import load_evaluator\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load environment variables (optional since we're not using OpenAI)\n",
    "load_dotenv()\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    \"\"\"Calculate cosine distance between two vectors.\"\"\"\n",
    "    return 1 - cosine_similarity(a, b)\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Calculate Euclidean distance between two vectors.\"\"\"\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "def compare_words_advanced(embedding_function, word1, word2):\n",
    "    \"\"\"Advanced comparison between two words using multiple metrics.\"\"\"\n",
    "    print(f\"\\nğŸ” Advanced comparison between '{word1}' and '{word2}':\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get embeddings\n",
    "    vector1 = embedding_function.embed_query(word1)\n",
    "    vector2 = embedding_function.embed_query(word2)\n",
    "    \n",
    "    # Calculate different similarity metrics\n",
    "    cos_sim = cosine_similarity(vector1, vector2)\n",
    "    cos_dist = cosine_distance(vector1, vector2)\n",
    "    eucl_dist = euclidean_distance(vector1, vector2)\n",
    "    \n",
    "    print(f\"ğŸ“Š Cosine Similarity: {cos_sim:.4f}\")\n",
    "    print(f\"ğŸ“ Cosine Distance: {cos_dist:.4f}\")\n",
    "    print(f\"ğŸ“ Euclidean Distance: {eucl_dist:.4f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if cos_sim > 0.8:\n",
    "        print(\"ğŸ’š Very similar words\")\n",
    "    elif cos_sim > 0.6:\n",
    "        print(\"ğŸ’› Moderately similar words\")\n",
    "    elif cos_sim > 0.4:\n",
    "        print(\"ğŸ§¡ Somewhat similar words\")\n",
    "    else:\n",
    "        print(\"â¤ï¸ Quite different words\")\n",
    "    \n",
    "    return {\n",
    "        'cosine_similarity': cos_sim,\n",
    "        'cosine_distance': cos_dist,\n",
    "        'euclidean_distance': eucl_dist\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate embeddings and word comparisons.\"\"\"\n",
    "    print(\"ğŸ¤— Starting HuggingFace Embeddings Demo...\")\n",
    "    \n",
    "    # Initialize HuggingFace embeddings\n",
    "    print(\"ğŸ“¥ Loading HuggingFace embeddings model...\")\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    print(\"âœ… HuggingFace embeddings loaded successfully!\")\n",
    "    \n",
    "    # Get embedding for a single word\n",
    "    test_word = \"apple\"\n",
    "    print(f\"\\nğŸ Getting embedding for '{test_word}'...\")\n",
    "    vector = embedding_function.embed_query(test_word)\n",
    "    \n",
    "    print(f\"ğŸ“Š Vector for '{test_word}': {vector[:5]}... (showing first 5 dimensions)\")\n",
    "    print(f\"ğŸ“ Vector length: {len(vector)} dimensions\")\n",
    "    print(f\"ğŸ”¢ Vector data type: {type(vector[0])}\")\n",
    "    \n",
    "    # Compare different word pairs\n",
    "    word_pairs = [\n",
    "        (\"apple\", \"iphone\"),      # Related tech/brand\n",
    "        (\"apple\", \"orange\"),      # Related fruits\n",
    "        (\"car\", \"automobile\"),    # Synonyms\n",
    "        (\"happy\", \"sad\"),         # Opposites\n",
    "        (\"dog\", \"computer\"),      # Unrelated\n",
    "        (\"king\", \"queen\"),        # Related concepts\n",
    "        (\"paris\", \"france\"),      # Related geography\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ” Comparing {len(word_pairs)} word pairs...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    for word1, word2 in word_pairs:\n",
    "        result = compare_words_advanced(embedding_function, word1, word2)\n",
    "        results.append((word1, word2, result))\n",
    "    \n",
    "    # Try using LangChain's built-in evaluator (if available)\n",
    "    print(f\"\\nğŸ§ª Testing LangChain's built-in evaluator...\")\n",
    "    try:\n",
    "        evaluator = load_evaluator(\"pairwise_embedding_distance\", embeddings=embedding_function)\n",
    "        test_pair = (\"apple\", \"iphone\")\n",
    "        langchain_result = evaluator.evaluate_string_pairs(\n",
    "            prediction=test_pair[0], \n",
    "            prediction_b=test_pair[1]\n",
    "        )\n",
    "        print(f\"âœ… LangChain evaluator result for {test_pair}: {langchain_result}\")\n",
    "    except Exception as eval_error:\n",
    "        print(f\"âš ï¸ LangChain evaluator failed: {eval_error}\")\n",
    "        print(\"ğŸ’¡ Using manual comparison methods instead (which work great!)\")\n",
    "    \n",
    "    # Summary of results\n",
    "    print(f\"\\nğŸ“ˆ Summary of Word Pair Similarities:\")\n",
    "    print(\"=\" * 60)\n",
    "    sorted_results = sorted(results, key=lambda x: x[2]['cosine_similarity'], reverse=True)\n",
    "    \n",
    "    for i, (word1, word2, metrics) in enumerate(sorted_results, 1):\n",
    "        similarity = metrics['cosine_similarity']\n",
    "        print(f\"{i:2d}. {word1:10} â†” {word2:10} | Similarity: {similarity:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_embedding_quality():\n",
    "    \"\"\"Test the quality of embeddings with different types of words.\"\"\"\n",
    "    print(\"\\nğŸ§ª Testing embedding quality with different word types...\")\n",
    "    \n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    \n",
    "    # Test categories\n",
    "    test_categories = {\n",
    "        \"Animals\": [\"dog\", \"cat\", \"elephant\", \"mouse\"],\n",
    "        \"Colors\": [\"red\", \"blue\", \"green\", \"yellow\"],\n",
    "        \"Countries\": [\"france\", \"germany\", \"japan\", \"brazil\"],\n",
    "        \"Emotions\": [\"happy\", \"sad\", \"angry\", \"excited\"],\n",
    "        \"Technology\": [\"computer\", \"smartphone\", \"internet\", \"software\"]\n",
    "    }\n",
    "    \n",
    "    for category, words in test_categories.items():\n",
    "        print(f\"\\nğŸ“‚ Category: {category}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Compare first word with others in the same category\n",
    "        base_word = words[0]\n",
    "        for other_word in words[1:]:\n",
    "            result = compare_words_advanced(embedding_function, base_word, other_word)\n",
    "            # Just show the similarity score for brevity\n",
    "            similarity = result['cosine_similarity']\n",
    "            print(f\"  {base_word} â†” {other_word}: {similarity:.3f}\")\n",
    "\n",
    "def query_similar_words(word, word_list, top_k=3):\n",
    "    \"\"\"Find the most similar words from a list to a given word.\"\"\"\n",
    "    print(f\"\\nğŸ¯ Finding words most similar to '{word}'...\")\n",
    "    \n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    \n",
    "    target_vector = embedding_function.embed_query(word)\n",
    "    similarities = []\n",
    "    \n",
    "    for candidate_word in word_list:\n",
    "        if candidate_word.lower() != word.lower():  # Skip the same word\n",
    "            candidate_vector = embedding_function.embed_query(candidate_word)\n",
    "            similarity = cosine_similarity(target_vector, candidate_vector)\n",
    "            similarities.append((candidate_word, similarity))\n",
    "    \n",
    "    # Sort by similarity and get top_k\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar = similarities[:top_k]\n",
    "    \n",
    "    print(f\"ğŸ† Top {top_k} most similar words to '{word}':\")\n",
    "    for i, (similar_word, similarity) in enumerate(top_similar, 1):\n",
    "        print(f\"  {i}. {similar_word}: {similarity:.4f}\")\n",
    "    \n",
    "    return top_similar\n",
    "\n",
    "# Execution logic\n",
    "if __name__ == \"__main__\":\n",
    "    # If running as script\n",
    "    main()\n",
    "    test_embedding_quality()\n",
    "    \n",
    "    # Example of finding similar words\n",
    "    word_bank = [\"apple\", \"orange\", \"banana\", \"computer\", \"laptop\", \"phone\", \n",
    "                 \"car\", \"bicycle\", \"happy\", \"joyful\", \"sad\", \"angry\"]\n",
    "    query_similar_words(\"apple\", word_bank)\n",
    "    \n",
    "else:\n",
    "    # If imported in Jupyter notebook\n",
    "    print(\"ğŸ¤— HuggingFace Embeddings Tool loaded!\")\n",
    "    print(\"\\nğŸš€ Available functions:\")\n",
    "    print(\"  â€¢ main() - Run complete demo\")\n",
    "    print(\"  â€¢ compare_words_advanced(embedding_function, word1, word2) - Compare two words\")\n",
    "    print(\"  â€¢ test_embedding_quality() - Test embeddings across categories\")\n",
    "    print(\"  â€¢ query_similar_words(word, word_list) - Find similar words\")\n",
    "    print(\"\\nğŸ’¡ Quick start: Run main()\")\n",
    "\n",
    "# Auto-run demo (uncomment to auto-execute)\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14534380-bbe6-45c0-aaf4-8fac51202ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting RAG Query System Demo...\n",
      "ğŸ” Testing with 8 different queries...\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Query 1/8: 'How does Alice meet the Mad Hatter?'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'How does Alice meet the Mad Hatter?'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'How does Alice meet the Mad Hatter?'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.540\n",
      "ğŸ“ Content preview: â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 82827\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.519\n",
      "ğŸ“ Content preview: Alice waited a little, half expecting to see it again, but it did not\n",
      "appear, and after a minute or two she walked on in the direction in\n",
      "which the Ma...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 70057\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.478\n",
      "ğŸ“ Content preview: â€œHave you guessed the riddle yet?â€ the Hatter said, turning to Alice\n",
      "again.\n",
      "\n",
      "â€œNo, I give it up,â€ Alice replied: â€œwhatâ€™s the answer?â€\n",
      "\n",
      "â€œI havenâ€™t the s...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 75797\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.470\n",
      "ğŸ“ Content preview: â€œWhoâ€™s making personal remarks now?â€ the Hatter asked triumphantly.\n",
      "\n",
      "Alice did not quite know what to say to this: so she helped herself to\n",
      "some tea a...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 80253\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.470\n",
      "ğŸ“ Content preview: The Hatter was the first to break the silence. â€œWhat day of the month\n",
      "is it?â€ he said, turning to Alice: he had taken his watch out of his\n",
      "pocket, and...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 74110\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.540\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"How does Alice meet the Mad Hatter?\"\n",
      "\n",
      "**Relevant Content:**\n",
      "â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter.\n",
      "\n",
      "---\n",
      "\n",
      "Alice waited a little, half expecting to see it again, but it did not\n",
      "appear, and after a minute or two she walked on in the direction in\n",
      "which the March Hare was said to live. â€œIâ€™ve seen hatters before,â€ she\n",
      "said to herself; â€œthe March Hare will be much the most interesting, and\n",
      "\n",
      "---\n",
      "\n",
      "â€œHave you guessed the riddle yet?â€ the Hatter said, turning to Alice\n",
      "again.\n",
      "\n",
      "â€œNo, I give it up,â€ Alice replied: â€œwhatâ€™s the answer?â€\n",
      "\n",
      "â€œI havenâ€™t the slightest idea,â€ said the Hatter.\n",
      "\n",
      "â€œNor I,â€ said the March Hare.\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 2/8: 'Alice Mad Hatter meeting'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'Alice Mad Hatter meeting'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'Alice Mad Hatter meeting'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.522\n",
      "ğŸ“ Content preview: â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 82827\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.473\n",
      "ğŸ“ Content preview: The Hatter was the first to break the silence. â€œWhat day of the month\n",
      "is it?â€ he said, turning to Alice: he had taken his watch out of his\n",
      "pocket, and...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 74110\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.470\n",
      "ğŸ“ Content preview: â€œIs that the way you manage?â€ Alice asked.\n",
      "\n",
      "The Hatter shook his head mournfully. â€œNot I!â€ he replied. â€œWe\n",
      "quarrelled last Marchâ€”just before he went m...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 77170\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.453\n",
      "ğŸ“ Content preview: â€œTell us a story!â€ said the March Hare.\n",
      "\n",
      "â€œYes, please do!â€ pleaded Alice.\n",
      "\n",
      "â€œAnd be quick about it,â€ added the Hatter, â€œor youâ€™ll be asleep again\n",
      "befor...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 79113\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.433\n",
      "ğŸ“ Content preview: Alice waited a little, half expecting to see it again, but it did not\n",
      "appear, and after a minute or two she walked on in the direction in\n",
      "which the Ma...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 70057\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.522\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"Alice Mad Hatter meeting\"\n",
      "\n",
      "**Relevant Content:**\n",
      "â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter.\n",
      "\n",
      "---\n",
      "\n",
      "The Hatter was the first to break the silence. â€œWhat day of the month\n",
      "is it?â€ he said, turning to Alice: he had taken his watch out of his\n",
      "pocket, and was looking at it uneasily, shaking it every now and then,\n",
      "and holding it to his ear.\n",
      "\n",
      "Alice considered a little, and then said â€œThe fourth.â€\n",
      "\n",
      "---\n",
      "\n",
      "â€œIs that the way you manage?â€ Alice asked.\n",
      "\n",
      "The Hatter shook his head mournfully. â€œNot I!â€ he replied. â€œWe\n",
      "quarrelled last Marchâ€”just before he went mad, you knowâ€”â€ (pointing\n",
      "with his tea spoon at the March Hare,) â€œâ€”it was at the great concert\n",
      "given by the Queen of Hearts, and I had to sing\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 3/8: 'Alice encounters Mad Hatter'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'Alice encounters Mad Hatter'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'Alice encounters Mad Hatter'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.569\n",
      "ğŸ“ Content preview: â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 82827\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.520\n",
      "ğŸ“ Content preview: Alice waited a little, half expecting to see it again, but it did not\n",
      "appear, and after a minute or two she walked on in the direction in\n",
      "which the Ma...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 70057\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.507\n",
      "ğŸ“ Content preview: â€œThereâ€™s no such thing!â€ Alice was beginning very angrily, but the\n",
      "Hatter and the March Hare went â€œSh! sh!â€ and the Dormouse sulkily\n",
      "remarked, â€œIf you...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 80630\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.506\n",
      "ğŸ“ Content preview: â€œHave you guessed the riddle yet?â€ the Hatter said, turning to Alice\n",
      "again.\n",
      "\n",
      "â€œNo, I give it up,â€ Alice replied: â€œwhatâ€™s the answer?â€\n",
      "\n",
      "â€œI havenâ€™t the s...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 75797\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.487\n",
      "ğŸ“ Content preview: â€œIs that the way you manage?â€ Alice asked.\n",
      "\n",
      "The Hatter shook his head mournfully. â€œNot I!â€ he replied. â€œWe\n",
      "quarrelled last Marchâ€”just before he went m...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 77170\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.569\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"Alice encounters Mad Hatter\"\n",
      "\n",
      "**Relevant Content:**\n",
      "â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter.\n",
      "\n",
      "---\n",
      "\n",
      "Alice waited a little, half expecting to see it again, but it did not\n",
      "appear, and after a minute or two she walked on in the direction in\n",
      "which the March Hare was said to live. â€œIâ€™ve seen hatters before,â€ she\n",
      "said to herself; â€œthe March Hare will be much the most interesting, and\n",
      "\n",
      "---\n",
      "\n",
      "â€œThereâ€™s no such thing!â€ Alice was beginning very angrily, but the\n",
      "Hatter and the March Hare went â€œSh! sh!â€ and the Dormouse sulkily\n",
      "remarked, â€œIf you canâ€™t be civil, youâ€™d better finish the story for\n",
      "yourself.â€\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 4/8: 'Mad Hatter Alice first meeting'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'Mad Hatter Alice first meeting'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'Mad Hatter Alice first meeting'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.512\n",
      "ğŸ“ Content preview: â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 82827\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.490\n",
      "ğŸ“ Content preview: The Hatter was the first to break the silence. â€œWhat day of the month\n",
      "is it?â€ he said, turning to Alice: he had taken his watch out of his\n",
      "pocket, and...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 74110\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.465\n",
      "ğŸ“ Content preview: â€œI didnâ€™t know it was your table,â€ said Alice; â€œitâ€™s laid for a great\n",
      "many more than three.â€\n",
      "\n",
      "â€œYour hair wants cutting,â€ said the Hatter. He had been ...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 72591\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.461\n",
      "ğŸ“ Content preview: â€œIs that the way you manage?â€ Alice asked.\n",
      "\n",
      "The Hatter shook his head mournfully. â€œNot I!â€ he replied. â€œWe\n",
      "quarrelled last Marchâ€”just before he went m...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 77170\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.449\n",
      "ğŸ“ Content preview: â€œTell us a story!â€ said the March Hare.\n",
      "\n",
      "â€œYes, please do!â€ pleaded Alice.\n",
      "\n",
      "â€œAnd be quick about it,â€ added the Hatter, â€œor youâ€™ll be asleep again\n",
      "befor...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 79113\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.512\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"Mad Hatter Alice first meeting\"\n",
      "\n",
      "**Relevant Content:**\n",
      "â€œReally, now you ask me,â€ said Alice, very much confused, â€œI donâ€™t\n",
      "thinkâ€”â€\n",
      "\n",
      "â€œThen you shouldnâ€™t talk,â€ said the Hatter.\n",
      "\n",
      "---\n",
      "\n",
      "The Hatter was the first to break the silence. â€œWhat day of the month\n",
      "is it?â€ he said, turning to Alice: he had taken his watch out of his\n",
      "pocket, and was looking at it uneasily, shaking it every now and then,\n",
      "and holding it to his ear.\n",
      "\n",
      "Alice considered a little, and then said â€œThe fourth.â€\n",
      "\n",
      "---\n",
      "\n",
      "â€œI didnâ€™t know it was your table,â€ said Alice; â€œitâ€™s laid for a great\n",
      "many more than three.â€\n",
      "\n",
      "â€œYour hair wants cutting,â€ said the Hatter. He had been looking at\n",
      "Alice for some time with great curiosity, and this was his first\n",
      "speech.\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 5/8: 'Alice tea party'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'Alice tea party'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'Alice tea party'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.573\n",
      "ğŸ“ Content preview: â€œAt any rate Iâ€™ll never go there again!â€ said Alice as she picked her\n",
      "way through the wood. â€œItâ€™s the stupidest tea-party I ever was at in\n",
      "all my life...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 83311\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.459\n",
      "ğŸ“ Content preview: CHAPTER VII.\n",
      "A Mad Tea-Party...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 71550\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.442\n",
      "ğŸ“ Content preview: â€œHow dreadfully savage!â€ exclaimed Alice.\n",
      "\n",
      "â€œAnd ever since that,â€ the Hatter went on in a mournful tone, â€œhe wonâ€™t\n",
      "do a thing I ask! Itâ€™s always six o...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 78057\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.378\n",
      "ğŸ“ Content preview: â€œHave some wine,â€ the March Hare said in an encouraging tone.\n",
      "\n",
      "Alice looked all round the table, but there was nothing on it but tea.\n",
      "â€œI donâ€™t see any...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 72221\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.350\n",
      "ğŸ“ Content preview: â€œTake some more tea,â€ the March Hare said to Alice, very earnestly.\n",
      "\n",
      "â€œIâ€™ve had nothing yet,â€ Alice replied in an offended tone, â€œso I canâ€™t\n",
      "take more....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 79964\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.573\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"Alice tea party\"\n",
      "\n",
      "**Relevant Content:**\n",
      "â€œAt any rate Iâ€™ll never go there again!â€ said Alice as she picked her\n",
      "way through the wood. â€œItâ€™s the stupidest tea-party I ever was at in\n",
      "all my life!â€\n",
      "\n",
      "---\n",
      "\n",
      "CHAPTER VII.\n",
      "A Mad Tea-Party\n",
      "\n",
      "---\n",
      "\n",
      "â€œHow dreadfully savage!â€ exclaimed Alice.\n",
      "\n",
      "â€œAnd ever since that,â€ the Hatter went on in a mournful tone, â€œhe wonâ€™t\n",
      "do a thing I ask! Itâ€™s always six oâ€™clock now.â€\n",
      "\n",
      "A bright idea came into Aliceâ€™s head. â€œIs that the reason so many\n",
      "tea-things are put out here?â€ she asked.\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 6/8: 'White Rabbit'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'White Rabbit'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'White Rabbit'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.422\n",
      "ğŸ“ Content preview: surprise, when the White Rabbit read out, at the top of his shrill\n",
      "little voice, the name â€œAlice!â€...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 132025\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.417\n",
      "ğŸ“ Content preview: So Alice began telling them her adventures from the time when she first\n",
      "saw the White Rabbit. She was a little nervous about it just at first,\n",
      "the two...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 117035\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.413\n",
      "ğŸ“ Content preview: After a time she heard a little pattering of feet in the distance, and\n",
      "she hastily dried her eyes to see what was coming. It was the White\n",
      "Rabbit retu...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 14266\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.400\n",
      "ğŸ“ Content preview: Alice watched the White Rabbit as he fumbled over the list, feeling\n",
      "very curious to see what the next witness would be like, â€œâ€”for they\n",
      "havenâ€™t got mu...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 131824\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.392\n",
      "ğŸ“ Content preview: ornamented with hearts. Next came the guests, mostly Kings and Queens,\n",
      "and among them Alice recognised the White Rabbit: it was talking in a\n",
      "hurried n...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 86424\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.422\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"White Rabbit\"\n",
      "\n",
      "**Relevant Content:**\n",
      "surprise, when the White Rabbit read out, at the top of his shrill\n",
      "little voice, the name â€œAlice!â€\n",
      "\n",
      "---\n",
      "\n",
      "So Alice began telling them her adventures from the time when she first\n",
      "saw the White Rabbit. She was a little nervous about it just at first,\n",
      "the two creatures got so close to her, one on each side, and opened\n",
      "their eyes and mouths so very wide, but she gained courage as she\n",
      "\n",
      "---\n",
      "\n",
      "After a time she heard a little pattering of feet in the distance, and\n",
      "she hastily dried her eyes to see what was coming. It was the White\n",
      "Rabbit returning, splendidly dressed, with a pair of white kid gloves\n",
      "in one hand and a large fan in the other: he came trotting along in a\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 7/8: 'What happens in Alice in Wonderland?'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'What happens in Alice in Wonderland?'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'What happens in Alice in Wonderland?'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.507\n",
      "ğŸ“ Content preview: There was a dead silence instantly, and Alice thought to herself, â€œI\n",
      "wonder what they will do next! If they had any sense, theyâ€™d take the\n",
      "roof off.â€ ...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 41389\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.479\n",
      "ğŸ“ Content preview: Alice could think of nothing else to say but â€œIt belongs to the\n",
      "Duchess: youâ€™d better ask her about it.â€\n",
      "\n",
      "â€œSheâ€™s in prison,â€ the Queen said to the exe...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 97352\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.475\n",
      "ğŸ“ Content preview: Just at this moment Alice felt a very curious sensation, which puzzled\n",
      "her a good deal until she made out what it was: she was beginning to\n",
      "grow large...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 126821\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.474\n",
      "ğŸ“ Content preview: In another moment down went Alice after it, never once considering how\n",
      "in the world she was to get out again....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 2680\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.461\n",
      "ğŸ“ Content preview: There were doors all round the hall, but they were all locked; and when\n",
      "Alice had been all the way down one side and up the other, trying every\n",
      "door, ...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 6936\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.507\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"What happens in Alice in Wonderland?\"\n",
      "\n",
      "**Relevant Content:**\n",
      "There was a dead silence instantly, and Alice thought to herself, â€œI\n",
      "wonder what they will do next! If they had any sense, theyâ€™d take the\n",
      "roof off.â€ After a minute or two, they began moving about again, and\n",
      "Alice heard the Rabbit say, â€œA barrowful will do, to begin with.â€\n",
      "\n",
      "---\n",
      "\n",
      "Alice could think of nothing else to say but â€œIt belongs to the\n",
      "Duchess: youâ€™d better ask her about it.â€\n",
      "\n",
      "â€œSheâ€™s in prison,â€ the Queen said to the executioner: â€œfetch her here.â€\n",
      "And the executioner went off like an arrow.\n",
      "\n",
      "---\n",
      "\n",
      "Just at this moment Alice felt a very curious sensation, which puzzled\n",
      "her a good deal until she made out what it was: she was beginning to\n",
      "grow larger again, and she thought at first she would get up and leave\n",
      "the court; but on second thoughts she decided to remain where she was\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“ Query 8/8: 'Who is the Cheshire Cat?'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¯ Processing question: 'Who is the Cheshire Cat?'\n",
      "================================================================================\n",
      "ğŸ¤— Initializing HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace embeddings loaded successfully!\n",
      "ğŸ“š Database loaded from chroma\n",
      "ğŸ” Searching for: 'Who is the Cheshire Cat?'\n",
      "ğŸ“Š Found 5 results:\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 1 - Relevance Score: 0.467\n",
      "ğŸ“ Content preview: was a little startled by seeing the Cheshire Cat sitting on a bough of\n",
      "a tree a few yards off....\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 67588\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 2 - Relevance Score: 0.465\n",
      "ğŸ“ Content preview: watching it a minute or two, she made it out to be a grin, and she said\n",
      "to herself â€œItâ€™s the Cheshire Cat: now I shall have somebody to talk\n",
      "to.â€...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 92811\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 3 - Relevance Score: 0.442\n",
      "ğŸ“ Content preview: rather a handsome pig, I think.â€ And she began thinking over other\n",
      "children she knew, who might do very well as pigs, and was just saying\n",
      "to herself, ...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 67380\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 4 - Relevance Score: 0.409\n",
      "ğŸ“ Content preview: The Queen smiled and passed on.\n",
      "\n",
      "â€œWho are you talking to?â€ said the King, going up to Alice, and\n",
      "looking at the Catâ€™s head with great curiosity.\n",
      "\n",
      "â€œItâ€™...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 94250\n",
      "------------------------------------------------------------\n",
      "ğŸ“„ Result 5 - Relevance Score: 0.401\n",
      "ğŸ“ Content preview: â€œItâ€™s a friend of mineâ€”a Cheshire Cat,â€ said Alice: â€œallow me to\n",
      "introduce it.â€\n",
      "\n",
      "â€œI donâ€™t like the look of it at all,â€ said the King: â€œhowever, it may...\n",
      "ğŸ“ Source: data\\books\\alice_in_wonderland.md\n",
      "ğŸ“ Start index: 94396\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ Best relevance score: 0.467\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– **RESPONSE:**\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ **Context-Based Answer:**\n",
      "\n",
      "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"Who is the Cheshire Cat?\"\n",
      "\n",
      "**Relevant Content:**\n",
      "was a little startled by seeing the Cheshire Cat sitting on a bough of\n",
      "a tree a few yards off.\n",
      "\n",
      "---\n",
      "\n",
      "watching it a minute or two, she made it out to be a grin, and she said\n",
      "to herself â€œItâ€™s the Cheshire Cat: now I shall have somebody to talk\n",
      "to.â€\n",
      "\n",
      "---\n",
      "\n",
      "rather a handsome pig, I think.â€ And she began thinking over other\n",
      "children she knew, who might do very well as pigs, and was just saying\n",
      "to herself, â€œif one only knew the right way to change themâ€”â€ when she\n",
      "was a little startled by seeing the Cheshire Cat sitting on a bough of\n",
      "\n",
      "**Sources:** data\\books\\alice_in_wonderland.md\n",
      "\n",
      "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„\n",
      "\n",
      "ğŸ“Š **SUMMARY OF ALL QUERIES:**\n",
      "================================================================================\n",
      "âœ…  1. How does Alice meet the Mad Hatter?                | Score: 0.540 | Sources: 1\n",
      "âœ…  2. Alice Mad Hatter meeting                           | Score: 0.522 | Sources: 1\n",
      "âœ…  3. Alice encounters Mad Hatter                        | Score: 0.569 | Sources: 1\n",
      "âœ…  4. Mad Hatter Alice first meeting                     | Score: 0.512 | Sources: 1\n",
      "âœ…  5. Alice tea party                                    | Score: 0.573 | Sources: 1\n",
      "âš ï¸  6. White Rabbit                                       | Score: 0.422 | Sources: 1\n",
      "âœ…  7. What happens in Alice in Wonderland?               | Score: 0.507 | Sources: 1\n",
      "âš ï¸  8. Who is the Cheshire Cat?                           | Score: 0.467 | Sources: 1\n"
     ]
    }
   ],
   "source": [
    "# RAG Query System with HuggingFace Embeddings\n",
    "# Complete code for Jupyter Notebook - No OpenAI dependencies\n",
    "\n",
    "import argparse\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables (optional)\n",
    "load_dotenv()\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "---\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "def initialize_embeddings():\n",
    "    \"\"\"Initialize HuggingFace embeddings.\"\"\"\n",
    "    print(\"ğŸ¤— Initializing HuggingFace embeddings...\")\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    print(\"âœ… HuggingFace embeddings loaded successfully!\")\n",
    "    return embedding_function\n",
    "\n",
    "def initialize_database():\n",
    "    \"\"\"Initialize the Chroma database with HuggingFace embeddings.\"\"\"\n",
    "    if not os.path.exists(CHROMA_PATH):\n",
    "        print(f\"âŒ Database not found at {CHROMA_PATH}\")\n",
    "        print(\"ğŸ’¡ Please run the data store generation script first!\")\n",
    "        return None\n",
    "    \n",
    "    embedding_function = initialize_embeddings()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "    print(f\"ğŸ“š Database loaded from {CHROMA_PATH}\")\n",
    "    return db\n",
    "\n",
    "def search_documents(db, query_text, k=5):\n",
    "    \"\"\"Search for relevant documents in the database.\"\"\"\n",
    "    print(f\"ğŸ” Searching for: '{query_text}'\")\n",
    "    \n",
    "    # Search the DB\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=k)\n",
    "    \n",
    "    # Debug: Show what we found\n",
    "    print(f\"ğŸ“Š Found {len(results)} results:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"ğŸ“„ Result {i} - Relevance Score: {score:.3f}\")\n",
    "        print(f\"ğŸ“ Content preview: {doc.page_content[:150]}...\")\n",
    "        print(f\"ğŸ“ Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"ğŸ“ Start index: {doc.metadata.get('start_index', 'N/A')}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_response_simple(results, query_text):\n",
    "    \"\"\"Generate a simple response without using ChatGPT/OpenAI.\"\"\"\n",
    "    if not results:\n",
    "        return \"âŒ No relevant documents found to answer your question.\"\n",
    "    \n",
    "    # Create context from top results\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for doc, score in results[:3]:  # Use top 3 results\n",
    "        if score > 0.3:  # Lower threshold for HuggingFace embeddings\n",
    "            context_parts.append(doc.page_content)\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            if source not in sources:\n",
    "                sources.append(source)\n",
    "    \n",
    "    if not context_parts:\n",
    "        return \"âŒ No sufficiently relevant documents found.\"\n",
    "    \n",
    "    context_text = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Simple response without LLM\n",
    "    response = f\"\"\"\n",
    "ğŸ“‹ **Context-Based Answer:**\n",
    "\n",
    "Based on the relevant text passages found, here are the key excerpts that relate to your question: \"{query_text}\"\n",
    "\n",
    "**Relevant Content:**\n",
    "{context_text}\n",
    "\n",
    "**Sources:** {', '.join(sources)}\n",
    "\n",
    "ğŸ’¡ **Note:** This is a context-based response. The relevant passages above should contain information to answer your question.\n",
    "\"\"\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "def generate_response_with_local_llm(results, query_text):\n",
    "    \"\"\"Generate response using a local LLM approach (placeholder for future enhancement).\"\"\"\n",
    "    # This could be enhanced with local models like Ollama, Hugging Face transformers, etc.\n",
    "    print(\"ğŸš§ Local LLM integration not implemented yet.\")\n",
    "    print(\"ğŸ“‹ Falling back to context-based response...\")\n",
    "    return generate_response_simple(results, query_text)\n",
    "\n",
    "def query_documents(question: str, use_llm=False):\n",
    "    \"\"\"\n",
    "    Query documents with a specific question.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to ask\n",
    "        use_llm (bool): Whether to try using a local LLM (not implemented yet)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response data or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nğŸ¯ Processing question: '{question}'\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Initialize database\n",
    "        db = initialize_database()\n",
    "        if db is None:\n",
    "            return None\n",
    "        \n",
    "        # Search for relevant documents\n",
    "        results = search_documents(db, question, k=5)\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            print(f\"âŒ No results found for query: '{question}'\")\n",
    "            return None\n",
    "        \n",
    "        # Check relevance scores\n",
    "        best_score = results[0][1] if results else 0\n",
    "        print(f\"ğŸ¯ Best relevance score: {best_score:.3f}\")\n",
    "        \n",
    "        if best_score < 0.2:  # Lower threshold for HuggingFace\n",
    "            print(\"âš ï¸ Low relevance scores. Results may not be very relevant.\")\n",
    "        \n",
    "        # Generate response\n",
    "        if use_llm:\n",
    "            response_text = generate_response_with_local_llm(results, question)\n",
    "        else:\n",
    "            response_text = generate_response_simple(results, question)\n",
    "        \n",
    "        # Collect sources\n",
    "        sources = [doc.metadata.get(\"source\", \"Unknown\") for doc, _score in results[:3]]\n",
    "        context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results[:3]])\n",
    "        \n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"response\": response_text,\n",
    "            \"sources\": list(set(sources)),  # Remove duplicates\n",
    "            \"context\": context_text,\n",
    "            \"relevance_scores\": [score for _, score in results[:3]]\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ¤– **RESPONSE:**\")\n",
    "        print(\"=\" * 80)\n",
    "        print(response_text)\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate multiple query variations.\"\"\"\n",
    "    print(\"ğŸš€ Starting RAG Query System Demo...\")\n",
    "    \n",
    "    # Try different variations of queries\n",
    "    queries_to_try = [\n",
    "        \"How does Alice meet the Mad Hatter?\",\n",
    "        \"Alice Mad Hatter meeting\",\n",
    "        \"Alice encounters Mad Hatter\", \n",
    "        \"Mad Hatter Alice first meeting\",\n",
    "        \"Alice tea party\",\n",
    "        \"White Rabbit\",\n",
    "        \"What happens in Alice in Wonderland?\",\n",
    "        \"Who is the Cheshire Cat?\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ” Testing with {len(queries_to_try)} different queries...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for i, query_text in enumerate(queries_to_try, 1):\n",
    "        print(f\"\\nğŸ“ Query {i}/{len(queries_to_try)}: '{query_text}'\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        result = query_documents(query_text)\n",
    "        if result:\n",
    "            results_summary.append({\n",
    "                \"query\": query_text,\n",
    "                \"best_score\": max(result[\"relevance_scores\"]) if result[\"relevance_scores\"] else 0,\n",
    "                \"sources\": result[\"sources\"]\n",
    "            })\n",
    "        else:\n",
    "            results_summary.append({\n",
    "                \"query\": query_text,\n",
    "                \"best_score\": 0,\n",
    "                \"sources\": []\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + \"ğŸ”„\" * 40)\n",
    "    \n",
    "    # Summary of all queries\n",
    "    print(f\"\\nğŸ“Š **SUMMARY OF ALL QUERIES:**\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, summary in enumerate(results_summary, 1):\n",
    "        score = summary[\"best_score\"]\n",
    "        query = summary[\"query\"]\n",
    "        sources_count = len(summary[\"sources\"])\n",
    "        \n",
    "        status = \"âœ…\" if score > 0.5 else \"âš ï¸\" if score > 0.2 else \"âŒ\"\n",
    "        print(f\"{status} {i:2d}. {query[:50]:<50} | Score: {score:.3f} | Sources: {sources_count}\")\n",
    "\n",
    "def interactive_mode():\n",
    "    \"\"\"Interactive mode for asking custom questions.\"\"\"\n",
    "    print(\"ğŸª **Interactive Query Mode**\")\n",
    "    print(\"Type your questions (or 'quit' to exit):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    db = initialize_database()\n",
    "    if db is None:\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"\\nâ“ Your question: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"ğŸ‘‹ Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            if not question:\n",
    "                print(\"Please enter a question.\")\n",
    "                continue\n",
    "            \n",
    "            result = query_documents(question)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# Execution logic\n",
    "if __name__ == \"__main__\":\n",
    "    # If running as script\n",
    "    main()\n",
    "    \n",
    "    # Uncomment to run interactive mode\n",
    "    # interactive_mode()\n",
    "    \n",
    "else:\n",
    "    # If imported in Jupyter notebook\n",
    "    print(\"ğŸ“š RAG Query System loaded!\")\n",
    "    print(\"\\nğŸš€ Available functions:\")\n",
    "    print(\"  â€¢ main() - Run demo with multiple queries\")\n",
    "    print(\"  â€¢ query_documents('your question') - Ask a specific question\")\n",
    "    print(\"  â€¢ interactive_mode() - Start interactive question mode\")\n",
    "    print(\"  â€¢ initialize_database() - Load the vector database\")\n",
    "    print(\"\\nğŸ’¡ Quick start: Run main() or query_documents('your question')\")\n",
    "    print(\"\\nâš ï¸ Note: Make sure you've created the vector database first!\")\n",
    "\n",
    "# Auto-run demo (uncomment to auto-execute)\n",
    "# main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ragproto)",
   "language": "python",
   "name": "ragproto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
